{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytrends\n",
      "  Downloading pytrends-4.9.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytrends) (2.31.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytrends) (2.2.1)\n",
      "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytrends) (5.3.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.25->pytrends) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.25->pytrends) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.25->pytrends) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.25->pytrends) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.0->pytrends) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.0->pytrends) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.0->pytrends) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.0->pytrends) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=0.25->pytrends) (1.16.0)\n",
      "Downloading pytrends-4.9.2-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pytrends\n",
      "Successfully installed pytrends-4.9.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.153.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n",
      "Downloading google_api_python_client-2.153.0-py2.py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.7/221.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uritemplate, pyasn1, proto-plus, httplib2, googleapis-common-protos, cachetools, rsa, pyasn1-modules, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.5.0 google-api-core-2.23.0 google-api-python-client-2.153.0 google-auth-2.36.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.66.0 httplib2-0.22.0 proto-plus-1.25.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 rsa-4.9 uritemplate-4.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytrends\n",
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "# 셀레니움 사용\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException, NoSuchElementException, TimeoutException\n",
    "import time\n",
    "# 구글 트랜드 사용\n",
    "from pytrends.request import TrendReq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_partial_results(data_dict, data_col_name, filename=\"partial.csv\"):\n",
    "    \"\"\"\n",
    "    중간 데이터 저장 함수 정의\n",
    "    \"\"\"\n",
    "    partial_data = {\n",
    "        'year': list(data_dict.keys()),\n",
    "        data_col_name: list(data_dict.values()),\n",
    "    }\n",
    "    # Pandas DataFrame으로 변환 후 저장\n",
    "    pd.DataFrame(partial_data).to_csv(filename, index=False)\n",
    "    print(f\"부분 데이터가 {filename}에 저장되었습니다!\")\n",
    "\n",
    "def get_article_counts_by_year():\n",
    "    '''\n",
    "    연도별로 프로야구 관련 기사 개수를 크롤링한다.\n",
    "    리턴값: 2010년부터 2024년까지 기사 개수를 년도: 기사 개수 딕셔너리 형태로 리턴\n",
    "    '''\n",
    "    total_articles_counts = {year: 0 for year in range(2010, 2025)}\n",
    "    for year in range(2010, 2025):\n",
    "        for month in range(1, 13):\n",
    "            for day in range(1, 32):\n",
    "                # 날짜 형식 맞추기 (예: 20240101)\n",
    "                date = f\"{year}{month:02}{day:02}\"\n",
    "\n",
    "                # 날짜 유효성 검사\n",
    "                try:\n",
    "                    time.strptime(date, \"%Y%m%d\")  # 유효하지 않은 날짜는 ValueError 발생\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                # 하루 기사 개수 계산\n",
    "                daily_articles = get_daily_article_count(date)\n",
    "                total_articles_counts[year] += daily_articles\n",
    "                print(f\"{date} 기사 개수: {daily_articles}개 / 총: {total_articles_counts[year]}개\")\n",
    "        save_partial_results(total_articles_counts, 'article_counts_by_year', f\"{year}_partial_y_aud_arti.csv\")\n",
    "    return total_articles_counts\n",
    "\n",
    "def get_daily_article_count(date):\n",
    "    '''\n",
    "    하루의 기사 개수를 리턴합니다.\n",
    "    리턴값: int\n",
    "    '''\n",
    "    total_post_counts = 0\n",
    "    # Selenium Chromedriver 설정\n",
    "    chromedriver_path = \"/usr/local/bin/chromedriver\"  # Chromedriver 경로\n",
    "    service = Service(chromedriver_path)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    # 네이버 야구 페이지 이동\n",
    "    base_url = f\"https://sports.news.naver.com/kbaseball/news/index?isphoto=N&view=photo&date={date}&type=latest\"\n",
    "    try: \n",
    "        driver.get(base_url)\n",
    "        time.sleep(5)  # 페이지 로딩 대기\n",
    "\n",
    "        # 전체 페이지 수 가져오기\n",
    "        try:\n",
    "            while True:\n",
    "                total_pages_element = driver.find_element(By.CSS_SELECTOR, \"div.paginate\")\n",
    "                total_pages = total_pages_element.text.split()\n",
    "                print(total_pages)\n",
    "                # 마지막 페이지 찾기\n",
    "                if total_pages[-1] == \"다음\":\n",
    "                    next_button = driver.find_element(By.CLASS_NAME, \"next\")\n",
    "                    next_button.click()\n",
    "                    time.sleep(2)\n",
    "                else: # 마지막 페이지 기사 개수 + 30 * (마지막 페이지 개수 - 1)\n",
    "                    try: \n",
    "                        last_page_id = total_pages[-1]\n",
    "                        last_page_button = driver.find_element(By.CSS_SELECTOR, f\"a[data-id='{last_page_id}']\")\n",
    "                        last_page_button.click()\n",
    "                        time.sleep(2)\n",
    "                    except Exception as e:\n",
    "                        print(f\"{date}: {e}\")\n",
    "                        \n",
    "                        \n",
    "                    ul_selector = \"div.news_list2 > ul\"  # ul 태그의 선택자\n",
    "                    li_selector = f\"{ul_selector} > li\"  # ul 아래 li 선택자\n",
    "                    li_elements = driver.find_elements(By.CSS_SELECTOR, li_selector)\n",
    "                    total_post_counts = (int(last_page_id)-1) * 30 + len(li_elements)\n",
    "                    # print(f\"ul 아래 li 개수: {len(li_elements)}개\")\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "\n",
    "        # 드라이버 종료\n",
    "        driver.quit()\n",
    "        # print(f\"{date} 기사 개수: {total_post_counts}\")\n",
    "        return total_post_counts\n",
    "    except WebDriverException as e:\n",
    "        print(f\"URL 로드 중 오류 발생: {e}\")\n",
    "        return 0\n",
    "\n",
    "def get_web_search_by_year():\n",
    "    \"\"\"\n",
    "    구글 트랜드를 이용한 연도별 웹 검색량을 크롤링한다.\n",
    "    리턴값: 2010~2024년 웹 검색량을 {'year': 검색량} 형태의 딕셔너리로 반환.\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl=\"ko\", tz=360)\n",
    "    keywords = [\"야구\", \"KBO\", \"야구장\", \"프로야구\"]\n",
    "\n",
    "    # 요청 딜레이 및 에러 방지\n",
    "    try:\n",
    "        pytrends.build_payload(keywords, timeframe=\"2010-01-01 2024-12-31\", geo=\"KR\")\n",
    "        trends = pytrends.interest_over_time()\n",
    "    except Exception as e:\n",
    "        print(f\"데이터 요청 실패: {e}\")\n",
    "        return {}\n",
    "\n",
    "    # 데이터 처리\n",
    "    if not trends.empty:\n",
    "        trends = trends.reset_index()  # 날짜(date)를 열로 변환\n",
    "        trends[\"year\"] = trends[\"date\"].dt.year  # 연도 추출\n",
    "\n",
    "        # 연도별 합산\n",
    "        yearly_trends = trends.groupby(\"year\")[[\"야구\", \"KBO\", \"야구장\", \"프로야구\"]].sum()\n",
    "\n",
    "        # 모든 키워드의 합산 열 추가\n",
    "        yearly_trends[\"web_search_by_years\"] = yearly_trends.sum(axis=1)\n",
    "\n",
    "        # 연도별 총 검색량 딕셔너리로 반환\n",
    "        web_search_counts = yearly_trends[\"web_search_by_years\"].to_dict()\n",
    "        return web_search_counts\n",
    "    else:\n",
    "        print(\"데이터가 비어 있습니다.\")\n",
    "        return {}\n",
    "\n",
    "# def get_kbo_youtube_views_by_year():\n",
    "#     '''\n",
    "#     연도별 KBO 유튜브 조회수를 크롤링한다.\n",
    "#     리턴값: ~2024년까지 유튜브 조회수를 리스트로 리턴\n",
    "#     '''\n",
    "\n",
    "# # 중간 데이터 저장 함수 정의\n",
    "# def save_partial_results(likes_counts, post_counts, filename=\"partial_y_a_insta.csv\"):\n",
    "#     \"\"\"\n",
    "#     likes_counts와 post_counts 데이터를 지정된 파일에 저장합니다.\n",
    "#     \"\"\"\n",
    "#     partial_data = {\n",
    "#         'year': list(likes_counts.keys()),\n",
    "#         'instagram_likes_by_year': list(likes_counts.values()),\n",
    "#         'instagram_posts_by_year': list(post_counts.values()),\n",
    "#     }\n",
    "#     # Pandas DataFrame으로 변환 후 저장\n",
    "#     pd.DataFrame(partial_data).to_csv(filename, index=False)\n",
    "#     print(f\"부분 데이터가 {filename}에 저장되었습니다!\")\n",
    "    \n",
    "def get_instagram_data_by_year():\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.common.action_chains import ActionChains\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from selenium import webdriver\n",
    "    import time\n",
    "\n",
    "    # Chromedriver 경로 설정\n",
    "    chromedriver_path = \"/usr/local/bin/chromedriver\"\n",
    "    service = Service(chromedriver_path)\n",
    "    dr = webdriver.Chrome(service=service)\n",
    "    dr.set_window_size(414, 800)\n",
    "    dr.set_page_load_timeout(300)\n",
    "\n",
    "    # Instagram 로그인\n",
    "    dr.get('https://www.instagram.com/')\n",
    "    time.sleep(2)\n",
    "    id_box = WebDriverWait(dr, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#loginForm > div > div:nth-child(1) > div > label > input\")))\n",
    "    password_box = dr.find_element(By.CSS_SELECTOR, \"#loginForm > div > div:nth-child(2) > div > label > input\")\n",
    "    login_button = dr.find_element(By.CSS_SELECTOR, '#loginForm > div > div:nth-child(3) > button')\n",
    "    id_box.send_keys(\"sksohn01@sookmyung.ac.kr\")\n",
    "    password_box.send_keys(\"sks0hn01!!\")\n",
    "    login_button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # KBO 계정으로 이동\n",
    "    dr.get(\"https://www.instagram.com/kbo.official/\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 좋아요 수 및 게시물 수 계산\n",
    "    likes_counts = {year: 0 for year in range(2010, 2025)}\n",
    "    post_counts = {year: 0 for year in range(2010, 2025)}\n",
    "\n",
    "    # 무한 스크롤\n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "    last_height = dr.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        dr.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = dr.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # 게시물 처리\n",
    "    cards = dr.find_elements(By.CLASS_NAME, '_aagw')\n",
    "    for i in range(len(cards)):\n",
    "        retries = 0\n",
    "        while retries < 3:  # 재시도 최대 3회\n",
    "            try:\n",
    "                cards = dr.find_elements(By.CLASS_NAME, '_aagw')  # 매번 요소 재참조\n",
    "                card = cards[i]\n",
    "\n",
    "                # 스크롤 후 클릭\n",
    "                dr.execute_script(\"arguments[0].scrollIntoView(true);\", card)\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 강제 클릭\n",
    "                ActionChains(dr).move_to_element(card).click().perform()\n",
    "                time.sleep(2)\n",
    "\n",
    "                # 좋아요 데이터 처리\n",
    "                like_element = WebDriverWait(dr, 30).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, 'x193iq5w.xeuugli.x1fj9vlw.x13faqbe.x1vvkbs.xt0psk2.x1i0vuye.xvs91rp.x1s688f.x10wh9bi.x1wdrske.x8viiok.x18hxmgj'))\n",
    "                )\n",
    "                likes = like_element.text.replace(\"좋아요 \", \"\").replace(\"개\", \"\").strip()\n",
    "                if \"만\" in likes:\n",
    "                    likes = float(likes[:-1]) * 10000\n",
    "\n",
    "                # 업로드 연도 가져오기\n",
    "                time_element = WebDriverWait(dr, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'time.x1p4m5qa')))\n",
    "                upload_time = int(time_element.get_attribute('datetime')[:4])\n",
    "\n",
    "                # 데이터 누적\n",
    "                likes_counts[upload_time] += int(likes)\n",
    "                post_counts[upload_time] += 1\n",
    "                break  # 성공적으로 처리했으면 재시도 루프 종료\n",
    "            except Exception as e:\n",
    "                retries += 1\n",
    "                print(f\"게시물 {i+1} 클릭 중 오류 발생, 재시도 {retries}/3: {e}\")\n",
    "        else:\n",
    "            print(f\"게시물 {i+1} 처리 실패, 다음 게시물로 넘어갑니다.\")\n",
    "\n",
    "        # 뒤로가기\n",
    "        dr.back()\n",
    "        time.sleep(2)\n",
    "\n",
    "    dr.quit()\n",
    "    return likes_counts, post_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인기도 칼럼 수집: 관중수(audience_by_year), 연도별 기사 개수(article_counts_by_year), 크보 유튜브 조회수(kbo_youtube_views_by_year), 인스타그램 해시태그 언급량(instagram_hashtags_by_year), 방송 시청률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연도별 기사 개수, 관중수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연도별 기사 개수, 관중수 구하기\n",
    "################ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 실행 금지\n",
    "##############################################################\n",
    "year = [\n",
    "    2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
    "    2020, 2021, 2022, 2023, 2024\n",
    "]\n",
    "audience_by_year = [\n",
    "    5928626, 6810028, 7156157, 6441945, 6509915, 7360530, 8339577, 8400688, 8073742, 7286008, \n",
    "    328317, 1228489, 6076074, 8100326, 10887705\n",
    "]\n",
    "\n",
    "article_counts = get_article_counts_by_year()\n",
    "data = {'year': year,\n",
    "        'audience_by_year': audience_by_year,\n",
    "        'article_counts_by_year': list(article_counts.values()),\n",
    "}\n",
    "year_data = pd.DataFrame(data)\n",
    "# year_data.to_csv('y_aud_arti.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 검색량 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# 웹 검색량 데이터\n",
    "data = pd.read_csv(\"./y_aud_arti.csv\")\n",
    "\n",
    "web_search_counts = get_web_search_by_year()\n",
    "data['web_search_count_by_year'] = list(web_search_counts.values())\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv('add_web_search.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유튜브 조회수, 좋아요수, 댓글수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유튜브 조회수, 좋아요수, 댓글수 구하기\n",
    "\n",
    "data = pd.read_csv(\"./y_aud_arti.csv\")\n",
    "kbo_youtube_views = get_kbo_youtube_views_by_year()\n",
    "\n",
    "data['kbo_youtube_views_by_year'] = list(kbo_youtube_views.values())\n",
    "year_data = pd.DataFrame(data)\n",
    "year_data.to_csv('yaa_youtube.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> API key 설정\n",
      ">>> 대상 채널명: KBO\n",
      ">>> 대상 채널 ID: UCoVz66yWHzVsXAFG8WhJK9g\n",
      ">>> YouTube에서 해당 채널에 속한 모든 비디오 ID 확인 완료\n",
      ">>> 데이터 수집 준비 완료\n",
      ">>> 개별 비디오 데이터 수집 시작\n",
      "{'kind': 'youtube#videoListResponse', 'etag': 'kf8ed2lEE8sOT59XaEv6ESOEf8s', 'items': [{'kind': 'youtube#video', 'etag': 'm0Sdqej9yztdpyLTsvzGCH7dV3A', 'id': 'aSx_Ie97Vhs', 'snippet': {'publishedAt': '2024-11-16T16:43:53Z', 'channelId': 'UCoVz66yWHzVsXAFG8WhJK9g', 'title': \"[𝗢.𝗧.𝗥] '8회의 약속? 약속의 8회?' 어쨌든 만든 주인공 인터뷰(박성한, 최원준, 박영현)| 2024 WBSC 프리미어12 야구 국가대표 크보직캠\", 'description': '#프리미어12 #야구대표팀 #야구 \\n팀코리아 야구 대표팀 콘텐츠 \"오프 더 레코드! [O.T.R]\" \\n대한민국을 대표하는 선수들의 비하인드가 궁금하시면 구독🔔과 좋아요👍 부탁드립니다!\\n\\n\\n✉️ 광고/스폰서/협업 문의\\ngh@koreabaseball.or.kr\\n\\nKBO 리그는 오직 TVING에서! 📱✨\\n✉️ 광고/스폰서/협업 문의\\ngh@koreabaseball.or.kr\\n\\nKBO 리그는 오직 TVING에서! 📱✨', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/aSx_Ie97Vhs/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/aSx_Ie97Vhs/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/aSx_Ie97Vhs/hqdefault.jpg', 'width': 480, 'height': 360}, 'standard': {'url': 'https://i.ytimg.com/vi/aSx_Ie97Vhs/sddefault.jpg', 'width': 640, 'height': 480}, 'maxres': {'url': 'https://i.ytimg.com/vi/aSx_Ie97Vhs/maxresdefault.jpg', 'width': 1280, 'height': 720}}, 'channelTitle': 'KBO', 'tags': ['야구', 'kbo', '기아타이거즈', '한화이글스', '롯데자이언츠', '엘지트윈스', '두산베어스', 'ssg랜더스', '삼성라이온즈', 'kt위즈', '키움히어로즈', 'nc다이노스', 'kia타이거즈', 'lg트윈스', 'baseball', '한국야구', '프로야구', '하이라이트', '야구장', '포스트시즌'], 'categoryId': '17', 'liveBroadcastContent': 'none', 'defaultLanguage': 'ko', 'localized': {'title': \"[𝗢.𝗧.𝗥] '8회의 약속? 약속의 8회?' 어쨌든 만든 주인공 인터뷰(박성한, 최원준, 박영현)| 2024 WBSC 프리미어12 야구 국가대표 크보직캠\", 'description': '#프리미어12 #야구대표팀 #야구 \\n팀코리아 야구 대표팀 콘텐츠 \"오프 더 레코드! [O.T.R]\" \\n대한민국을 대표하는 선수들의 비하인드가 궁금하시면 구독🔔과 좋아요👍 부탁드립니다!\\n\\n\\n✉️ 광고/스폰서/협업 문의\\ngh@koreabaseball.or.kr\\n\\nKBO 리그는 오직 TVING에서! 📱✨\\n✉️ 광고/스폰서/협업 문의\\ngh@koreabaseball.or.kr\\n\\nKBO 리그는 오직 TVING에서! 📱✨'}, 'defaultAudioLanguage': 'ko'}, 'contentDetails': {'duration': 'PT3M29S', 'dimension': '2d', 'definition': 'hd', 'caption': 'false', 'licensedContent': True, 'contentRating': {}, 'projection': 'rectangular'}, 'statistics': {'viewCount': '43016', 'likeCount': '1460', 'favoriteCount': '0', 'commentCount': '183'}}], 'pageInfo': {'totalResults': 1, 'resultsPerPage': 1}}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m         likes\u001b[38;5;241m.\u001b[39mappend(lc)\n\u001b[1;32m     94\u001b[0m         comments\u001b[38;5;241m.\u001b[39mappend(cc)\n\u001b[0;32m---> 95\u001b[0m         upload_date\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpA\u001b[49m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>> 개별 비디오 데이터 수집 완료\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>> 비디오 URL 정리\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pA' is not defined"
     ]
    }
   ],
   "source": [
    "# 라이브러리 임포트\n",
    "from googleapiclient.discovery import build\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "''' 아래 \"<--change here-->\" 에 자신의 API-Key를 입력하면 됩니다.\n",
    "'''\n",
    "\n",
    "\n",
    "# API key와 YouTube API 버전을 세팅\n",
    "api_key = \"AIzaSyBpWqno1zpgTXq0xw2AxiPj3fCFyZkPRCQ\"\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "print('>>> API key 설정')\n",
    "\n",
    "# 유튜브 모든 채널에는 'Uploads'라는 기본 채널이 있음\n",
    "# 해당 채널 ID를 가져온 뒤에, 해당 Uploads의 리스트를 다시 호출해오는 함수\n",
    "\n",
    "# 유튜브 데이터느 매일 변경됨. 오늘 날짜를 Last_update로 기록하기 위해 Datetime을 사용\n",
    "today = datetime.datetime.now()\n",
    "nowDate = today.strftime('%Y-%m-%d')\n",
    "\n",
    "# 채널id를 가지고 비디오 리스트를 가져오는 함수\n",
    "def get_channel_videos(channel_id):\n",
    "    # get Uploads playlist id\n",
    "    res = youtube.channels().list(id=channel_id, part='contentDetails').execute()\n",
    "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    res2 = youtube.channels().list(id=channel_id, part='snippet').execute()\n",
    "    channel_title = res2['items'][0]['snippet']['title']\n",
    "    print('>>> 대상 채널명: ' + channel_title)\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while 1:\n",
    "        res = youtube.playlistItems().list(playlistId=playlist_id,\n",
    "                                           part='snippet',\n",
    "                                           maxResults=50,\n",
    "                                           pageToken=next_page_token).execute()\n",
    "        videos += res['items']\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "\n",
    "    return videos\n",
    "\n",
    "# 채널의 ID를 입력하면, 그 채널에 속한 비디오를 추출\n",
    "chan_id = input(\"채널 아이디: \")\n",
    "videos = get_channel_videos(chan_id)\n",
    "\n",
    "print('>>> 대상 채널 ID: '+ chan_id)\n",
    "print('>>> YouTube에서 해당 채널에 속한 모든 비디오 ID 확인 완료')\n",
    "\n",
    "# 추출된 비디오 리스트에서 video ID만을 추출하여 list로 만든다.\n",
    "videoid_list = []\n",
    "for video in videos:\n",
    "    id_from_api = video['snippet']['resourceId']['videoId']\n",
    "    videoid_list.append(id_from_api)\n",
    "\n",
    "# videoid_list에 ID만 모두 추출하여 저장이 되었다.\n",
    "\n",
    "# 각 비디오에서 데이터를 추출하여, Dataframe을 만들기 위해 빈 list를 생성한다.\n",
    "title = []\n",
    "views = []\n",
    "likes = []\n",
    "# dislikes = []\n",
    "comments = []\n",
    "upload_date = []\n",
    "print('>>> 데이터 수집 준비 완료')\n",
    "\n",
    "# 각 비디오에서 데이터를 가져와서 리스트에 추가한다.\n",
    "print('>>> 개별 비디오 데이터 수집 시작')\n",
    "for i in range(len(videoid_list)):\n",
    "    # for i in range(200):\n",
    "    request = youtube.videos().list(part='snippet,contentDetails,statistics', id=videoid_list[i])\n",
    "    response = request.execute()\n",
    "\n",
    "    if response['items'] == []:\n",
    "        title.append('-')\n",
    "        views.append('-')\n",
    "        likes.append('-')\n",
    "        # dislikes.append('-')\n",
    "        comments.append('-')\n",
    "\n",
    "    else:\n",
    "        # result에서 추출\n",
    "        tname = response['items'][0]['snippet']['title']\n",
    "        vc = response['items'][0]['statistics']['viewCount']\n",
    "        lc = response['items'][0]['statistics']['likeCount']\n",
    "        dlc = response['items'][0]['statistics']['dislikeCount']\n",
    "        cc = response['items'][0]['statistics']['commentCount']\n",
    "        pA = response['items'][0]['snippet']['publishedAt']\n",
    "\n",
    "        # append\n",
    "        title.append(tname)\n",
    "        views.append(vc)\n",
    "        likes.append(lc)\n",
    "        # dislikes.append(dlc)\n",
    "        comments.append(cc)\n",
    "        upload_date.append(pA)\n",
    "\n",
    "print('>>> 개별 비디오 데이터 수집 완료')\n",
    "print('>>> 비디오 URL 정리')\n",
    "# YouTube API 응답에는 Video URL이 없음. 이를 생성하기 위해 prefix + Video ID로 리스트를 만든다.\n",
    "vidurl_prefix = 'https://www.youtube.com/watch?v='\n",
    "vidurl_list = []\n",
    "\n",
    "for i in range(len(videoid_list)):\n",
    "    vidurl = vidurl_prefix + videoid_list[i]\n",
    "    vidurl_list.append(vidurl)\n",
    "\n",
    "# Google API의 응답은 UTC를 기준으로 한다. KST로 변환이 필요하며, KST는 UTC+9이다.\n",
    "\n",
    "original_pubdate = []\n",
    "for i in range(len(upload_date)):\n",
    "    originaldate = upload_date[i]\n",
    "    convertedtime = datetime.datetime.strptime(originaldate, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    KSTdate = datetime.datetime.strptime(originaldate, '%Y-%m-%dT%H:%M:%SZ') + datetime.timedelta(hours=9)\n",
    "    KST_converted = KSTdate.strftime('%Y-%m-%d %H:%M')\n",
    "    original_pubdate.append(KST_converted)\n",
    "\n",
    "\n",
    "# 위에까지 생성된 모든 리스트를 하나의 데이터프레임으로 옮긴다.\n",
    "print('>>> 데이터프레임 형태로 가공')\n",
    "sum_df = pd.DataFrame([title, original_pubdate, videoid_list, vidurl_list, views, likes, comments]).T\n",
    "\n",
    "# 편의를 위해 컬럼 이름을 추가해준다.\n",
    "sum_df.columns = ['title', 'PublishedAt', 'ID', 'URL', 'views', 'likes', 'comments']\n",
    "\n",
    "# 유튜브 조회수는 매일 다르므로, 오늘 작업 날짜를 데이터프레임으로 추가한다. 시간은 무시한다.\n",
    "# 데이터 프레임에 넣기 전에, 비디오 개수만큼 날짜가 들어간 리스트를 만든다.\n",
    "date_list = []\n",
    "for i in range(len(videoid_list)):\n",
    "    date_list.append(nowDate)\n",
    "\n",
    "\n",
    "# 데이터프레임에 'Last_update_Date'을 추가한다.\n",
    "print('>>> 오늘 날짜(작업일) 기록 중')\n",
    "sum_df['Last_updated_Date'] = date_list\n",
    "\n",
    "# 채널명을 다시 가져온다.\n",
    "res2 = youtube.channels().list(id=chan_id, part='snippet').execute()\n",
    "channel_title = res2['items'][0]['snippet']['title']\n",
    "\n",
    "# 오늘 날짜가 들어간 csv 파일을 생성한다.\n",
    "print('>>> 작업이 완료되었습니다.')\n",
    "filename = channel_title + '_' + today.strftime('%Y%m%d') + '.csv'\n",
    "sum_df.to_csv(filename, encoding='utf-8-sig', index=False)\n",
    "print('결과물: ',filename)\n",
    "# CHANNEL_ID = \"UCoVz66yWHzVsXAFG8WhJK9g\"  # KBO 공식 채널 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
